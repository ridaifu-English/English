[1:17] it's harder to spot real information from something that's made up.
[1:21] So let's go back to the basics and explain why seeing isn't always believing.
[1:26] This is KN Explains: Outsmarting Deepfakes.
[1:30] What do people mean when they say deepfake?
[1:33] A deepfake is not a Photoshop trick or a filter.
[1:35] (Cat filter appears on speaker)
[1:37] It's most often an image, video, or audio clip that's been changed using artificial intelligence.
[1:43] The term deepfake has a dark history.
[1:46] It comes from a user on Reddit who went by the name deepfakes.
[1:50] The user deepfakes would make fake sexual videos of celebrities
[1:54] by swapping their faces onto bodies that weren't theirs.
[1:57] Even though the word fake is in the name,
[2:00] these deepfakes can often trick people into thinking something unreal is real.
[2:06] While some deepfakes can seem innocent enough, like this one,
[2:08] where the creator swaps the Spider-Man actor Tom Holland
[2:11] with the previous actor Tobey Maguire,
[2:14] and is totally upfront about it.
[2:16] Deepfakes can quickly become some serious stuff.
[2:19] It can be a personal attack.
[2:21] You might know or heard of someone who's had a deepfake made of them.
[2:25] (News headlines about AI-generated fake photos of students appear)
[2:26] Teens in parts of the U.S. and Canada are being victimized by deepfake nudes.
[2:31] It can be part of a crime or scam.
[2:33] Recently, a deepfake cost one company millions.
[2:37] 200 million Hong Kong dollars.
[2:39] That's about 34.7 million Canadian dollars,
[2:43] was transferred to a scammer after a businessman
[2:45] thought he was talking to his boss on a Zoom call.
[2:49] Turns out, that was a deepfake of someone impersonating his boss.
[2:54] Or they could affect wars, politics, and democracy.
[2:57] Like this manipulated video that appears to show
[2:59] Ukrainian President Volodymyr Zelenskyy telling his troops to surrender to Russian forces.
[3:05] It went viral online,
[3:07] and many who saw it thought it was real.
[3:10] So, if we can't always trust what we see and hear online,
[3:14] how do we spot deepfakes?
[3:16] And how do we know which information to trust?
[3:19] The experts we spoke to said the line between real and unreal is getting thinner.
[3:24] As artificial intelligence grows,
[3:26] deepfakes will become harder,
[3:28] if not impossible, to spot.
[3:31] Less than a year ago, I might have suggested looking at the hands of an image.
[3:35] (Clip from previous KN Explains video shown)
[3:36] AI generated content can look really real.
[3:39] Do you have any tips for spotting it?
[3:41] If you look at this Pope picture,
[3:42] he's actually not really holding the coffee mug,
[3:46] and it's just kind of below his hand.
[3:49] AI generated images and deepfakes used to struggle depicting hands,
[3:53] like in this example.
[3:56] Or in some deepfakes, the lighting can look all wrong and things can blend together.
[4:00] But deepfakes are getting more and more realistic
[4:03] at a faster and faster pace.
[4:05] So those tips aren't as useful anymore.
[4:08] One hack to outsmarting deepfakes is something we all need to practice.
[4:11] It's known as critical thinking.
[4:14] Before believing something you see, hear, or read,
[4:18] we have to stop and ask ourselves a few questions.
[4:21] Now, you've probably heard this before.
[4:23] It comes down to the five W's and one H.
[4:27] Who?
[4:27] Who is presenting this information and what is the source?
[4:31] Is it a TikTok video from an account you can't trace?
[4:34] Or a trusted news organization?
[4:36] Is it an official government or celebrity page?
[4:40] What?
[4:40] What is being said or shown?
[4:43] Is the information shocking?
[4:45] Does it seem too good to be true?
[4:47] Where?
[4:48] Where is this information coming from?
[4:51] What is the source?
[4:52] Can I track down where it was first posted?
[4:55] When?
[4:56] When was this information recorded?
[4:58] Can I verify it?
[5:00] Why?
[5:01] Why is this information being shown?
[5:04] Could there be an ulterior motive?
[5:06] How?
[5:07] Before I share or believe, I have to ask myself the final question.
[5:11] How do I know this is real?
[5:14] We've learned that we have to go a lot deeper beyond the surface to understand and spot deepfakes.
[5:20] And we now know that seeing is no longer the key to believing.